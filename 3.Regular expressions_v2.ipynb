{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"3.Regular expressions_v2.ipynb","provenance":[],"collapsed_sections":["cC5Dc_ha5c7w"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"FYd2uhN35c7f"},"source":["# Regular expressions"]},{"cell_type":"markdown","metadata":{"id":"Iovit8Y05c7h"},"source":["## Whats the purpose of regular expressions?\n","\n","Regular Expressions are extensively used for:\n","       \n","        1.To Extract insignts about the text ->  findall()\n","        2.To Clean the text -> sub()"]},{"cell_type":"markdown","metadata":{"id":"REHiLAWj5c7i"},"source":["Basic meta charecters used in regular expressions\n","\n","    . -> matches a single character\n","    * -> matches zero or more occourrence of the previous charecter\n","    + -> matches one or more occourrence of the previous charecter\n","    ^ -> matches any character start of a string\n","    $ -> matches any character end of a string\n","    [] -> matches one of the set of characters within []\n","    [a-z] -> matches on of the range of characters in lowercase alphabet\n","    [^abc] -> matches a character that is not a, b, or c"]},{"cell_type":"code","metadata":{"id":"82NirFAl5c7i"},"source":["import re\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wk4GLrX55c7j"},"source":["text = 'Around 2500 patients are taking part in clinical trails #Coronavirus'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1IJ-bWn75c7j","outputId":"16bb4049-85ee-44f3-dd22-038b538eb81c"},"source":["print(text)\n","re.findall('[a-z]+', text) # Find all sequency of lower case characters"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Around 2500 patients are taking part in clinical trails #Coronavirus\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['round',\n"," 'patients',\n"," 'are',\n"," 'taking',\n"," 'part',\n"," 'in',\n"," 'clinical',\n"," 'trails',\n"," 'oronavirus']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"FcZoVnLd5c7o","outputId":"05ee301f-8bf2-4fdf-ccb7-724f69f7a3d8"},"source":["print(text)\n","re.findall('[a-zA-Z]+', text) # Find all sequency of lower & upper case characters"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Around 2500 patients are taking part in clinical trails #Coronavirus\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['Around',\n"," 'patients',\n"," 'are',\n"," 'taking',\n"," 'part',\n"," 'in',\n"," 'clinical',\n"," 'trails',\n"," 'Coronavirus']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"qXHcVPGe5c7p"},"source":[" Extended Regular Expressions:\n"," \n","     \\d -> Any digit, equivalent to [0-9]\n","     \\D -> Any non-digit, equivalent to [^0-9]\n","    \\w -> Any alphanumeric, equivalent to [a-zA-Z0-9_]\n","    \\W -> Non-alphanumeric, equivalent to [^a-zA-Z0-9_]\n","    \\s -> Any whitespace character\n","    \\S -> Any nonwhitespace character\n","    \n","    () -> Scoping for extraction\n","    {} -> Frequency for extraction\n","    ? -> Make a pattern non greedy"]},{"cell_type":"code","metadata":{"id":"Ze2MwT5-5c7q","outputId":"ea96739d-01aa-4914-9ff9-0f2cdc94a123"},"source":["print(text)\n","re.findall('\\w+', text) # Find all sequency of word characters[a-zA-Z0-9_]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Around 2500 patients are taking part in clinical trails #Coronavirus\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['Around',\n"," '2500',\n"," 'patients',\n"," 'are',\n"," 'taking',\n"," 'part',\n"," 'in',\n"," 'clinical',\n"," 'trails',\n"," 'Coronavirus']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"R2RoIt9X5c7r"},"source":["text = \"The film Titanic was released in year 98 and was a hit till the year 2000 \\n5000 was the cost of the mobile\\ni baragined it to\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fljuhVJ15c7r","outputId":"86f9d334-046c-46fe-e662-3b34aed4249c"},"source":["print(text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The film Titanic was released in year 98 and was a hit till the year 2000 \n","5000 was the cost of the mobile\n","i baragined it to\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mFNFtzWJ5c7s","outputId":"b64be208-c5e0-4174-a1aa-5a62b0c7efa0"},"source":["for line in text.split(\"\\n\"):\n","    patterns = re.findall(\"\\d+\",line)\n","    if len(patterns)>0:\n","        print(patterns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['98', '2000']\n","['5000']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QFXICW7V5c7s","outputId":"83b34c98-52c5-4bec-b6cf-08febaafb597"},"source":["for line in text.split(\"\\n\"):\n","    line = line.strip()\n","    find = re.findall(\"\\d{4}\",line)\n","    if len(find)>0: \n","        print(find)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['2000']\n","['5000']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nsgr-dnk5c7t"},"source":["text = 'A message from csev@umich.edu to cwen@iupui.edu about meeting @2PM'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TTHQR7xD5c7t","outputId":"270a047c-6ec9-474b-bad4-62c61fc2e02c"},"source":["re.findall(\"\\S+@\\S+\", text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['csev@umich.edu', 'cwen@iupui.edu']"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"lmFFIb4m5c7u","outputId":"e6e660dd-6a7b-4fc1-fb7c-f7d0291fbae5"},"source":["re.findall(\"\\s+@\\S+\", text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[' @2PM']"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"KXbhKej75c7v","outputId":"8df1e0ab-ab03-4f4b-8dd2-6e947a535614"},"source":["re.findall(\"\\S+@(\\S+)\", text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['umich.edu', 'iupui.edu']"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"cS3iCfFo5c7v","outputId":"d3f28f1b-d722-45dc-ad3c-f431c2f7ac68"},"source":["re.findall(\"(\\S+)@\\S+\", text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['csev', 'cwen']"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"cC5Dc_ha5c7w"},"source":["#### Cleaning text using re.sub"]},{"cell_type":"code","metadata":{"id":"_9VCB3AG5c7w"},"source":["text = 'Around 2,500 patients are taking part in clinical trails #Coronavirus'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGt17sZ-5c7x","outputId":"f2c79049-83a9-4e4a-c85d-e9eca257ce3a"},"source":["print(text)\n","re.sub('[^\\w+]', '', text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Around 2,500 patients are taking part in clinical trails #Coronavirus\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'Around2500patientsaretakingpartinclinicaltrailsCoronavirus'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"9IS5w10T5c7x","outputId":"0ec873b6-262c-4f17-eda7-2a8d4e7cc849"},"source":["print(text)\n","re.sub('[^\\w+\\s]', '', text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Around 2,500 patients are taking part in clinical trails #Coronavirus\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'Around 2500 patients are taking part in clinical trails Coronavirus'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"f4dOcGUl5c7y"},"source":["text = \"film ABC  @ was ? produced %  in , year $ 1994  .  'by'   Mr_X\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9dzlDSSB5c7y","outputId":"8cd78de6-f491-4f0a-8d04-bb8c0dfbae5f"},"source":["#Removing special charecters with nothing\n","result1 = re.sub(\"[,@'?.$%_]\", \"\", text)\n","result1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'film ABC   was  produced   in  year  1994    by   MrX'"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"nWqSTskk5c78","outputId":"5117dfed-8532-472e-ef01-848773da68e2"},"source":["#Removing special charecters(non Alpha numeric and Space) with nothing\n","result1 = re.sub(\"[^a-zA-Z0-9 ]\",\"\",text)\n","result1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'film ABC   was  produced   in  year  1994    by   MrX'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"owNa3vcG5c79","outputId":"67fff07f-d2ac-4593-8245-1c18ce1ebf08"},"source":["# \\W -> Alphanumeric with underscores\n","#\\s -> Space\n","result1 = re.sub(\"[^\\w\\s]\",\"\",text)\n","result1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'film ABC   was  produced   in  year  1994    by   Mr_X'"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"umsK--xL5c79","outputId":"e983b3dd-1ef0-4021-b601-10d47b1d94e5"},"source":["#Removing multiple spaces with a single space\n","result = re.sub(\"\\s+\", \" \", result1)\n","result"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'film ABC was produced in year 1994 by Mr_X'"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"OR8EHAgR5c7-"},"source":["### Extracting text from HTML tags"]},{"cell_type":"code","metadata":{"id":"PioXi0yY5c7-"},"source":["text = \"\"\"<div>\n","<h1> H2O</h1>\n","<p> AutoML</p>\n","<a href=\"https://www.amazon.ai/products/h2o-driverless-ai/\"> Driverless AI</a>\n","</div>\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2-qO-qgF5c7-","outputId":"3e8029a8-6303-4929-c0e1-6c01346b3b5d"},"source":["print(text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<div>\n","<h1> H2O</h1>\n","<p> AutoML</p>\n","<a href=\"https://www.amazon.ai/products/h2o-driverless-ai/\"> Driverless AI</a>\n","</div>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cw_QUz8s5c7-"},"source":["To Extract Text Between the HTML tages we need to remove all the text between < and >\n","i.e remove  Zero or more occourrence of any chatecter between < and >"]},{"cell_type":"code","metadata":{"id":"STgRuGZZ5c7_","outputId":"ac035d40-38cc-4c94-c51e-53060db8ef5b"},"source":["print(re.sub('<.*>',\"\",text))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iJh6IdZx5c7_"},"source":["#.* and + are greedy - it matches everything including the closing angular bracket >\n","# .* and .+ should stop matching a pattern as soon as it encounters the closing angular bracket\n","# use a \"?\" along with .* and .+ to make it non greedy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OT0s38Kn5c7_","outputId":"9c487c1b-e7b1-4cad-d260-2a5dcb87897b"},"source":["print(re.sub('<.*?>',\"\",text))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," H2O\n"," AutoML\n"," Driverless AI\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AtVACSax5c8A"},"source":["## Extracting hashtags from tweets"]},{"cell_type":"code","metadata":{"id":"lONEdjjn5c8A","outputId":"35dd9ea8-ece1-451d-e325-645f5685c0b0"},"source":["text = 'Around 2,500 patients are taking part in clinical trails #Coronavirus'\n","print(text)\n","print(re.findall('#\\w+', text))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Around 2,500 patients are taking part in clinical trails #Coronavirus\n","['#Coronavirus']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uA-fwcm-5c8A","outputId":"36a7c268-bdbf-4aa7-d20d-f44402c25190"},"source":["tweets = pd.read_csv('C:/Users/Raghavendra N/OneDrive/Official/Datasets/tweets_donald_trump.csv')\n","tweets.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>created_at</th>\n","      <th>language</th>\n","      <th>likes</th>\n","      <th>retweets</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-06-17 03:27:56</td>\n","      <td>en</td>\n","      <td>123212.0</td>\n","      <td>18568.0</td>\n","      <td>96% Approval Rating in the Republican Party. T...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-06-17 02:45:33</td>\n","      <td>und</td>\n","      <td>0.0</td>\n","      <td>7942.0</td>\n","      <td>RT @TONYxTWO: @thejtlewis @JoeBiden https://t....</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2020-06-17 02:38:20</td>\n","      <td>en</td>\n","      <td>0.0</td>\n","      <td>23815.0</td>\n","      <td>RT @thejtlewis: “Trump isn’t going to accept t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2020-06-17 02:37:01</td>\n","      <td>en</td>\n","      <td>0.0</td>\n","      <td>6781.0</td>\n","      <td>RT @thejtlewis: With the utmost respect, I tha...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2020-06-17 02:31:11</td>\n","      <td>en</td>\n","      <td>56840.0</td>\n","      <td>14231.0</td>\n","      <td>A GREAT woman. Her son is looking down from he...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            created_at language     likes  retweets  \\\n","0  2020-06-17 03:27:56       en  123212.0   18568.0   \n","1  2020-06-17 02:45:33      und       0.0    7942.0   \n","2  2020-06-17 02:38:20       en       0.0   23815.0   \n","3  2020-06-17 02:37:01       en       0.0    6781.0   \n","4  2020-06-17 02:31:11       en   56840.0   14231.0   \n","\n","                                                text  \n","0  96% Approval Rating in the Republican Party. T...  \n","1  RT @TONYxTWO: @thejtlewis @JoeBiden https://t....  \n","2  RT @thejtlewis: “Trump isn’t going to accept t...  \n","3  RT @thejtlewis: With the utmost respect, I tha...  \n","4  A GREAT woman. Her son is looking down from he...  "]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"-I3ibrHu5c8B"},"source":["Obtain the frequency of each of the hashtags\n","\n","- Step1: Extract all the hash tags and store them in a list\n","- Step2: Compute the frequency of each of the hashtags"]},{"cell_type":"code","metadata":{"id":"dWk2-aKaxT0j"},"source":["all_hashtags = []\n","for row in tweets['text']:\n","    row_hashtags = re.findall('#\\w+', row)\n","    all_hashtags.extend(row_hashtags)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7lxQGBwxPHs"},"source":["len(all_hashtags)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pkiuHlVhxScJ"},"source":["all_hashtags[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p8hFuX-YxWXT"},"source":["freq_hashtags = pd.Series(all_hashtags).value_counts()\n","freq_hashtags.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l8gJuA5DxYoU"},"source":["#Task\n","all_userhandle = []\n","for row in tweets['text']:\n","    row_userhandle = re.findall('@\\w+', row)\n","    all_userhandle.extend(row_userhandle)\n","freq_userhandle = pd.Series(all_userhandle).value_counts()\n","freq_userhandle.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SPOHB-jP5c8M"},"source":["## Cleaning salary"]},{"cell_type":"code","metadata":{"id":"HT-q1qqx5c8N","outputId":"dbb2996c-cadc-4d3b-fc16-ba7267ed4ac4"},"source":["jobs = pd.read_csv('C:/Users/Raghavendra N/OneDrive/Official/Datasets/datascience_jobs.csv')\n","jobs.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>location</th>\n","      <th>experience</th>\n","      <th>skills</th>\n","      <th>company</th>\n","      <th>salary</th>\n","      <th>description</th>\n","      <th>posted_date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Data Science</td>\n","      <td>Mumbai</td>\n","      <td>2-4 yrs</td>\n","      <td>Algorithms, Machine Learning, Python, Java, Da...</td>\n","      <td>Netcore Solutions Pvt Ltd</td>\n","      <td>2,00,000 - 7,00,000 P.A.</td>\n","      <td>At least 2 year of experience in data engineer...</td>\n","      <td>1 day ago</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Analyst / Sr. Analyst (data Science)</td>\n","      <td>Gurgaon</td>\n","      <td>5-8 yrs</td>\n","      <td>predictive modeling, predictive analytics, mac...</td>\n","      <td>Cvent India Pvt. Ltd.</td>\n","      <td>5,00,000 - 10,00,000 P.A.</td>\n","      <td>Strong experience on providing predictive mode...</td>\n","      <td>Today</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ETL Lead &amp; Data Science</td>\n","      <td>Chennai, Bengaluru, Mumbai, Pune, Noida</td>\n","      <td>7-10 yrs</td>\n","      <td>SQL, Data Analysis, Text Mining, SAS, R, Stati...</td>\n","      <td>COMPUTER POWER GROUP PRIVATE LIMITED</td>\n","      <td>10,00,000 - 15,00,000 P.A.</td>\n","      <td>Industry experience in building and operationa...</td>\n","      <td>1 day ago</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Specialist - Data Science</td>\n","      <td>Delhi NCR, Bengaluru, Gurgaon</td>\n","      <td>7-12 yrs</td>\n","      <td>Specialist - Data Science, Data Science, data ...</td>\n","      <td>Brainsearch Consulting Pvt Ltd.Â</td>\n","      <td>Not disclosed</td>\n","      <td>- Experience with one or more data science pro...</td>\n","      <td>1 day ago</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Group Manager - Data Science - Python/nlp</td>\n","      <td>Bengaluru</td>\n","      <td>6-11 yrs</td>\n","      <td>machine learning, text mining, r, nlp, data sc...</td>\n","      <td>Staffio HR</td>\n","      <td>Not disclosed</td>\n","      <td>- This is a Team management role  - Skill set ...</td>\n","      <td>1 day ago</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       title  \\\n","0                               Data Science   \n","1       Analyst / Sr. Analyst (data Science)   \n","2                    ETL Lead & Data Science   \n","3                  Specialist - Data Science   \n","4  Group Manager - Data Science - Python/nlp   \n","\n","                                  location experience  \\\n","0                                   Mumbai    2-4 yrs   \n","1                                  Gurgaon    5-8 yrs   \n","2  Chennai, Bengaluru, Mumbai, Pune, Noida   7-10 yrs   \n","3            Delhi NCR, Bengaluru, Gurgaon   7-12 yrs   \n","4                                Bengaluru   6-11 yrs   \n","\n","                                              skills  \\\n","0  Algorithms, Machine Learning, Python, Java, Da...   \n","1  predictive modeling, predictive analytics, mac...   \n","2  SQL, Data Analysis, Text Mining, SAS, R, Stati...   \n","3  Specialist - Data Science, Data Science, data ...   \n","4  machine learning, text mining, r, nlp, data sc...   \n","\n","                                company                            salary  \\\n","0             Netcore Solutions Pvt Ltd        2,00,000 - 7,00,000 P.A.     \n","1                 Cvent India Pvt. Ltd.       5,00,000 - 10,00,000 P.A.     \n","2  COMPUTER POWER GROUP PRIVATE LIMITED      10,00,000 - 15,00,000 P.A.     \n","3     Brainsearch Consulting Pvt Ltd.Â                     Not disclosed    \n","4                            Staffio HR                    Not disclosed    \n","\n","                                         description posted_date  \n","0  At least 2 year of experience in data engineer...   1 day ago  \n","1  Strong experience on providing predictive mode...       Today  \n","2  Industry experience in building and operationa...   1 day ago  \n","3  - Experience with one or more data science pro...   1 day ago  \n","4  - This is a Team management role  - Skill set ...   1 day ago  "]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"9eJDMARm5c8N"},"source":["# Task : From the salary column extract the minimum and maximum salary, NA if unable to extract"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xAsUqLr5xcX8"},"source":["jobs['salary'].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWLeSx67xfrr"},"source":["salary = '5,00,000 - 10,00,000 P.A.'\n","re.findall('[0-9]+ - [0-9]+ P.A.', salary.replace(',', ''))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E_GqCgBixmXF"},"source":["def get_salary_min(row):\n","    row = row.replace(',', '')\n","    pattern = '([0-9]+) - [0-9]+ P.A.'\n","    salary = re.findall(pattern, row)\n","    if len(salary):\n","        return salary[0]\n","    else:\n","        return None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kSBgSKtexhYH"},"source":["jobs['salary_min'] = jobs['salary'].apply(get_salary_min)\n","jobs[['salary', 'salary_min']].head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jjp7fDtDxqle"},"source":["jobs['salary_min'] = pd.to_numeric(jobs['salary_min'],\n","                                  errors='coerce')\n","jobs['salary_min']"],"execution_count":null,"outputs":[]}]}